{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from scipy import sparse as ssp\n",
    "from sklearn.model_selection import KFold\n",
    "from sklearn.datasets import dump_svmlight_file, load_svmlight_file\n",
    "from sklearn.utils import resample, shuffle\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "seed=1024\n",
    "np.random.seed(seed)\n",
    "path = \"../../kaggle-quora/data/\"\n",
    "train = pd.read_csv(path+\"train_porter.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# tfidf\n",
    "train_question1_tfidf = pd.read_pickle(path+'train_question1_tfidf.pkl')[:]\n",
    "test_question1_tfidf = pd.read_pickle(path+'test_question1_tfidf.pkl')[:]\n",
    "\n",
    "train_question2_tfidf = pd.read_pickle(path+'train_question2_tfidf.pkl')[:]\n",
    "test_question2_tfidf = pd.read_pickle(path+'test_question2_tfidf.pkl')[:]\n",
    "\n",
    "\n",
    "train_question1_porter_tfidf = pd.read_pickle(path+'train_question1_porter_tfidf.pkl')[:]\n",
    "test_question1_porter_tfidf = pd.read_pickle(path+'test_question1_porter_tfidf.pkl')[:]\n",
    "\n",
    "train_question2_porter_tfidf = pd.read_pickle(path+'train_question2_porter_tfidf.pkl')[:]\n",
    "test_question2_porter_tfidf = pd.read_pickle(path+'test_question2_porter_tfidf.pkl')[:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Library/Frameworks/Python.framework/Versions/3.6/lib/python3.6/site-packages/ipykernel_launcher.py:2: FutureWarning: reshape is deprecated and will raise in a subsequent release. Please use .values.reshape(...) instead\n",
      "  \n",
      "/Library/Frameworks/Python.framework/Versions/3.6/lib/python3.6/site-packages/ipykernel_launcher.py:3: FutureWarning: reshape is deprecated and will raise in a subsequent release. Please use .values.reshape(...) instead\n",
      "  This is separate from the ipykernel package so we can avoid doing imports until\n",
      "/Library/Frameworks/Python.framework/Versions/3.6/lib/python3.6/site-packages/ipykernel_launcher.py:5: FutureWarning: reshape is deprecated and will raise in a subsequent release. Please use .values.reshape(...) instead\n",
      "  \"\"\"\n",
      "/Library/Frameworks/Python.framework/Versions/3.6/lib/python3.6/site-packages/ipykernel_launcher.py:6: FutureWarning: reshape is deprecated and will raise in a subsequent release. Please use .values.reshape(...) instead\n",
      "  \n"
     ]
    }
   ],
   "source": [
    "# interaction\n",
    "train_interaction = pd.read_pickle(path+'train_interaction.pkl')[:].reshape(-1,1)\n",
    "test_interaction = pd.read_pickle(path+'test_interaction.pkl')[:].reshape(-1,1)\n",
    "\n",
    "train_porter_interaction = pd.read_pickle(path+'train_porter_interaction.pkl')[:].reshape(-1,1)\n",
    "test_porter_interaction = pd.read_pickle(path+'test_porter_interaction.pkl')[:].reshape(-1,1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Library/Frameworks/Python.framework/Versions/3.6/lib/python3.6/site-packages/ipykernel_launcher.py:2: FutureWarning: reshape is deprecated and will raise in a subsequent release. Please use .values.reshape(...) instead\n",
      "  \n",
      "/Library/Frameworks/Python.framework/Versions/3.6/lib/python3.6/site-packages/ipykernel_launcher.py:3: FutureWarning: reshape is deprecated and will raise in a subsequent release. Please use .values.reshape(...) instead\n",
      "  This is separate from the ipykernel package so we can avoid doing imports until\n",
      "/Library/Frameworks/Python.framework/Versions/3.6/lib/python3.6/site-packages/ipykernel_launcher.py:5: FutureWarning: reshape is deprecated and will raise in a subsequent release. Please use .values.reshape(...) instead\n",
      "  \"\"\"\n",
      "/Library/Frameworks/Python.framework/Versions/3.6/lib/python3.6/site-packages/ipykernel_launcher.py:6: FutureWarning: reshape is deprecated and will raise in a subsequent release. Please use .values.reshape(...) instead\n",
      "  \n"
     ]
    }
   ],
   "source": [
    "# jaccard distance\n",
    "train_jaccard = pd.read_pickle(path+'train_jaccard.pkl')[:].reshape(-1,1)\n",
    "test_jaccard = pd.read_pickle(path+'test_jaccard.pkl')[:].reshape(-1,1)\n",
    "\n",
    "train_porter_jaccard = pd.read_pickle(path+'train_porter_jaccard.pkl')[:].reshape(-1,1)\n",
    "test_porter_jaccard = pd.read_pickle(path+'test_porter_jaccard.pkl')[:].reshape(-1,1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# len\n",
    "train_len = pd.read_pickle(path+\"train_len.pkl\")\n",
    "test_len = pd.read_pickle(path+\"test_len.pkl\")\n",
    "scaler = MinMaxScaler()\n",
    "scaler.fit(np.vstack([train_len, test_len]))\n",
    "train_len = scaler.transform(train_len)\n",
    "test_len =scaler.transform(test_len)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# jaccard + magic\n",
    "train_jac_magic = pd.read_pickle(path+'train_jaccard_magic_features.pkl').as_matrix()\n",
    "test_jac_magic = pd.read_pickle(path+'test_jaccard_magic_features.pkl').as_matrix()\n",
    "scaler = MinMaxScaler()\n",
    "scaler.fit(np.vstack([train_jac_magic, test_jac_magic]))\n",
    "train_jac_magic = scaler.transform(train_jac_magic)\n",
    "test_jac_magic =scaler.transform(test_jac_magic)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(404290, 3073589)\n",
      "(2345796, 3073589)\n",
      "CPU times: user 1min 10s, sys: 21.5 s, total: 1min 32s\n",
      "Wall time: 1min 39s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "X = ssp.hstack([\n",
    "    train_question1_tfidf,\n",
    "    train_question2_tfidf,\n",
    "    train_interaction,\n",
    "    train_porter_interaction,\n",
    "    train_jaccard,\n",
    "    train_porter_jaccard,\n",
    "    train_len,\n",
    "    train_jac_magic,\n",
    "    ]).tocsr()\n",
    "\n",
    "\n",
    "y = train['is_duplicate'].values[:]\n",
    "\n",
    "X_t = ssp.hstack([\n",
    "    test_question1_tfidf,\n",
    "    test_question2_tfidf,\n",
    "    test_interaction,\n",
    "    test_porter_interaction,\n",
    "    test_jaccard,\n",
    "    test_porter_jaccard,\n",
    "    test_len,\n",
    "    test_jac_magic,\n",
    "    ]).tocsr()\n",
    "\n",
    "\n",
    "print(X.shape)\n",
    "print(X_t.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'scipy.sparse.csr.csr_matrix'>\n",
      "<class 'numpy.ndarray'>\n"
     ]
    }
   ],
   "source": [
    "print(type(X))\n",
    "print(type(y))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "ssp.save_npz('./x_test.npz', ssp.csr_matrix(X_t))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def oversample(X_ot, y, p=0.165):\n",
    "    pos_ot = X_ot[y==1]\n",
    "    neg_ot = X_ot[y==0]\n",
    "    scale = ((pos_ot.shape[0]*1.0 / (pos_ot.shape[0] + neg_ot.shape[0])) / p) - 1\n",
    "    \n",
    "    while scale > 1:\n",
    "        neg_ot = ssp.vstack([neg_ot, neg_ot]).tocsr()\n",
    "        scale -=1\n",
    "\n",
    "    neg_ot = ssp.vstack([neg_ot, neg_ot[:int(scale * neg_ot.shape[0])]]).tocsr()\n",
    "    ot = ssp.vstack([pos_ot, neg_ot]).tocsr()\n",
    "    y=np.zeros(ot.shape[0])\n",
    "    y[:pos_ot.shape[0]]=1.0\n",
    "    print(y.mean())\n",
    "    \n",
    "    return ot, y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.191243661001\n"
     ]
    }
   ],
   "source": [
    "X_oversample, y_oversample = oversample(X, y, p=0.165)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "fold1_index = pd.read_csv('../index/fold1_index.csv').values.flatten()\n",
    "fold2_index = pd.read_csv('../index/fold2_index.csv').values.flatten()\n",
    "validation_index = pd.read_csv('../index/validation_index.csv').values.flatten()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "train_fold1 = X_oversample[fold1_index]\n",
    "train_fold2 = X_oversample[fold2_index]\n",
    "validation_fold = X_oversample[validation_index]\n",
    "\n",
    "y_train_fold1 = y_oversample[fold1_index]\n",
    "y_train_fold2 = y_oversample[fold2_index]\n",
    "y_validation_fold = y_oversample[validation_index]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'scipy.sparse.csr.csr_matrix'>\n",
      "<class 'scipy.sparse.csr.csr_matrix'>\n",
      "<class 'scipy.sparse.csr.csr_matrix'>\n",
      "<class 'scipy.sparse.csr.csr_matrix'>\n",
      "CPU times: user 23.2 s, sys: 1.68 s, total: 24.9 s\n",
      "Wall time: 25.4 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "########################################\n",
    "### Saving sparse matrix for py2 FM ###\n",
    "########################################\n",
    "\n",
    "print(type(train_fold1))\n",
    "print(type(train_fold2))\n",
    "print(type(ssp.csr_matrix(y_train_fold1)))\n",
    "print(type(ssp.csr_matrix(y_train_fold2)))\n",
    "\n",
    "ssp.save_npz('./x_train_fold1.npz', train_fold1)\n",
    "ssp.save_npz('./x_train_fold2.npz', train_fold2)\n",
    "ssp.save_npz('./x_validation_fold.npz', validation_fold)\n",
    "\n",
    "ssp.save_npz('./y_train_fold1.npz', ssp.csr_matrix(y_train_fold1))\n",
    "ssp.save_npz('./y_train_fold2.npz', ssp.csr_matrix(y_train_fold2))\n",
    "ssp.save_npz('./y_validation_fold.npz', ssp.csr_matrix(y_validation_fold))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "del train_fold1, train_fold2, validation_fold, y_train_fold1, y_train_fold2, y_validation_fold\n",
    "del X_oversample, y_oversample"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Load Data Directly Instead of Processing Again."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "##########################\n",
    "### Factorized Machine ###\n",
    "##########################\n",
    "\n",
    "from scipy import sparse\n",
    "from scipy.sparse import csc_matrix\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "from sklearn.datasets import dump_svmlight_file\n",
    "\n",
    "train_fold1 = sparse.load_npz(\"../../kaggle-quora/fm/x_train_fold1.npz\")\n",
    "train_fold2 = sparse.load_npz(\"../../kaggle-quora/fm/x_train_fold2.npz\")\n",
    "validation_fold = sparse.load_npz(\"../../kaggle-quora/fm/x_validation_fold.npz\")\n",
    "\n",
    "y_train_fold1 = sparse.load_npz(\"../../kaggle-quora/fm/y_train_fold1.npz\")\n",
    "y_train_fold2 = sparse.load_npz(\"../../kaggle-quora/fm/y_train_fold2.npz\")\n",
    "y_validation_fold = sparse.load_npz(\"../../kaggle-quora/fm/y_validation_fold.npz\")\n",
    "\n",
    "x_test = sparse.load_npz('../../kaggle-quora/fm/x_test.npz')\n",
    "\n",
    "x_train = sparse.vstack((train_fold1, train_fold2, validation_fold), format='csr')\n",
    "y_train = sparse.hstack((y_train_fold1, y_train_fold2, y_validation_fold), format='csr').T.toarray().flatten()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Fold:  1\n",
      "Train:  (624388, 3073589) (624388,)\n",
      "Val:  (156098, 3073589) (156098,)\n",
      "\n",
      "Fold:  2\n",
      "Train:  (624388, 3073589) (624388,)\n",
      "Val:  (156098, 3073589) (156098,)\n",
      "\n",
      "Fold:  3\n",
      "Train:  (624388, 3073589) (624388,)\n",
      "Val:  (156098, 3073589) (156098,)\n",
      "\n",
      "Fold:  4\n",
      "Train:  (624390, 3073589) (624390,)\n",
      "Val:  (156096, 3073589) (156096,)\n",
      "\n",
      "Fold:  5\n",
      "Train:  (624390, 3073589) (624390,)\n",
      "Val:  (156096, 3073589) (156096,)\n"
     ]
    }
   ],
   "source": [
    "# Generate 5 folds svm data for training...\n",
    "\n",
    "skf = StratifiedKFold(n_splits=5, random_state=None, shuffle=False)\n",
    "folds = 1\n",
    "for train_index, val_index in skf.split(x_train, y_train):\n",
    "    print('\\nFold: ', folds)\n",
    "    \n",
    "    x_train_fold = x_train[train_index]\n",
    "    y_train_fold = y_train[train_index]\n",
    "    print(\"Train: \", x_train_fold.shape, y_train_fold.shape)\n",
    "    \n",
    "    x_val_fold = x_train[val_index]\n",
    "    y_val_fold = y_train[val_index]\n",
    "    print(\"Val: \", x_val_fold.shape, y_val_fold.shape)\n",
    "    \n",
    "    dump_svmlight_file(x_train_fold, y_train_fold, \"./train_tfidf_jacad_magic_fold_{}.svm\".format(folds))\n",
    "    dump_svmlight_file(x_val_fold, y_val_fold, \"./val_tfidf_jacad_magic_fold_{}.svm\".format(folds))\n",
    "    folds = folds + 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# skf = KFold(n_splits=5, shuffle=True, random_state=seed).split(X)\n",
    "# for ind_tr, ind_te in skf:\n",
    "#     X_train = X[ind_tr]\n",
    "#     X_test = X[ind_te]\n",
    "\n",
    "#     y_train = y[ind_tr]\n",
    "#     y_test = y[ind_te]\n",
    "#     break\n",
    "\n",
    "dump_svmlight_file(X, y, path+\"X_tfidf_jacad_magic.svm\")\n",
    "del X\n",
    "dump_svmlight_file(X_t, np.zeros(X_t.shape[0]), path + \"X_t_tfidf_jacad_magic.svm\")\n",
    "del X_t"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.191269277687\n",
      "0.191144081052\n",
      "CPU times: user 3min 17s, sys: 8.93 s, total: 3min 26s\n",
      "Wall time: 3min 32s\n"
     ]
    }
   ],
   "source": [
    "# %%time\n",
    "\n",
    "# X_train, y_train = oversample(X_train.tocsr(), y_train, p=0.165)\n",
    "# X_test, y_test = oversample(X_test.tocsr(), y_test, p=0.165)\n",
    "\n",
    "# X_train, y_train = shuffle(X_train, y_train, random_state=seed)\n",
    "\n",
    "# dump_svmlight_file(X_train, y_train, path + \"X_train_tfidf_jacad_magic.svm\")\n",
    "# dump_svmlight_file(X_test, y_test, path + \"X_test_tfidf_jacad_magic.svm\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
